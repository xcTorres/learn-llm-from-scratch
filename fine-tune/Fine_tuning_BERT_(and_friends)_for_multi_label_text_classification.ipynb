{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLB3I4FKZ5Lr"
   },
   "source": [
    "# Fine-tuning BERT (and friends) for multi-label text classification\n",
    "\n",
    "In this notebook, we are going to fine-tune BERT to predict one or more labels for a given piece of text. Note that this notebook illustrates how to fine-tune a bert-base-uncased model, but you can also fine-tune a RoBERTa, DeBERTa, DistilBERT, CANINE, ... checkpoint in the same way. \n",
    "\n",
    "All of those work in the same way: they add a linear layer on top of the base model, which is used to produce a tensor of shape (batch_size, num_labels), indicating the unnormalized scores for a number of labels for every example in the batch.\n",
    "\n",
    "\n",
    "\n",
    "## Set-up environment\n",
    "\n",
    "First, we install the libraries which we'll use: HuggingFace Transformers and Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4wxY3x-ZZz8h",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mlx-python-sdk 0.3.0 requires bytedlogger<1.0.0,>=0.10.1, which is not installed.\n",
      "mlx-python-sdk 0.3.0 requires bytedtcc==1.*, which is not installed.\n",
      "mlx-python-sdk 0.3.0 requires bytedmetrics==0.9.*, but you have bytedmetrics 0.10.2 which is incompatible.\n",
      "mlx-python-sdk 0.3.0 requires fsspec==2022.*, but you have fsspec 2024.9.0 which is incompatible.\n",
      "mlx-python-sdk 0.3.0 requires packaging~=21.3, but you have packaging 24.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIH9NP0MZ6-O"
   },
   "source": [
    "## Load dataset\n",
    "\n",
    "Next, let's download a multi-label text classification dataset from the [hub](https://huggingface.co/).\n",
    "\n",
    "At the time of writing, I picked a random one as follows:   \n",
    "\n",
    "* first, go to the \"datasets\" tab on huggingface.co\n",
    "* next, select the \"multi-label-classification\" tag on the left as well as the the \"1k<10k\" tag (fo find a relatively small dataset).\n",
    "\n",
    "Note that you can also easily load your local data (i.e. csv files, txt files, Parquet files, JSON, ...) as explained [here](https://huggingface.co/docs/datasets/loading.html#local-and-remote-files).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "9a1aa9f2cc29473f9f8e5459d2641e76",
      "308fa6a7348140ec981a8d6c7d31f346",
      "8bc92587e35443488445e7521fbd0a13",
      "091f8220f33241f288faa0612853585f",
      "1045bb16e3694410898a73cf1b848917",
      "cb95e545fbdd4e99903bf634df694c9f",
      "5080d322a8034924b652b379c04667ed",
      "8b1899a0c4b144d7a5e6599f8afb8b65",
      "6111a73e684a47769bda7183a836ee91",
      "cd3570ddf67541d7818d97e236c54e54",
      "bbba60f793c14100934a268063f63d26"
     ]
    },
    "id": "sd1LiXGjZ420",
    "outputId": "1b5783cd-0e4e-4c92-c67c-57b9288f2381",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"sem_eval_2018_task_1\", \"subtask5.english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCL02vQgxYTO"
   },
   "source": [
    "As we can see, the dataset contains 3 splits: one for training, one for validation and one for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pRd1kXQZjYIY",
    "outputId": "8021590c-5607-4a9c-a474-bc57da503c93",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ID', 'Tweet', 'anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust'],\n",
       "        num_rows: 6838\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ID', 'Tweet', 'anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust'],\n",
       "        num_rows: 3259\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['ID', 'Tweet', 'anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust'],\n",
       "        num_rows: 886\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgS0wMWExcqP"
   },
   "source": [
    "Let's check the first example of the training split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "unjuTtKUjZI3",
    "outputId": "6f1e5051-8272-40f9-ced8-ba17a105e904",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': '2017-En-21441',\n",
       " 'Tweet': \"“Worry is a down payment on a problem you may never have'. \\xa0Joyce Meyer.  #motivation #leadership #worry\",\n",
       " 'anger': False,\n",
       " 'anticipation': True,\n",
       " 'disgust': False,\n",
       " 'fear': False,\n",
       " 'joy': False,\n",
       " 'love': False,\n",
       " 'optimism': True,\n",
       " 'pessimism': False,\n",
       " 'sadness': False,\n",
       " 'surprise': False,\n",
       " 'trust': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset['train'][0]\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DV0Rtetxgd4"
   },
   "source": [
    "The dataset consists of tweets, labeled with one or more emotions. \n",
    "\n",
    "Let's create a list that contains the labels, as well as 2 dictionaries that map labels to integers and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5vZhQpvkE8s",
    "outputId": "5d513b30-f209-492f-c6ab-245d64a67d40",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger',\n",
       " 'anticipation',\n",
       " 'disgust',\n",
       " 'fear',\n",
       " 'joy',\n",
       " 'love',\n",
       " 'optimism',\n",
       " 'pessimism',\n",
       " 'sadness',\n",
       " 'surprise',\n",
       " 'trust']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [label for label in dataset['train'].features.keys() if label not in ['ID', 'Tweet']]\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJ3Teyjmank2"
   },
   "source": [
    "## Preprocess data\n",
    "\n",
    "As models like BERT don't expect text as direct input, but rather `input_ids`, etc., we tokenize the text using the tokenizer. Here I'm using the `AutoTokenizer` API, which will automatically load the appropriate tokenizer based on the checkpoint on the hub.\n",
    "\n",
    "What's a bit tricky is that we also need to provide labels to the model. For multi-label text classification, this is a matrix of shape (batch_size, num_labels). Also important: this should be a tensor of floats rather than integers, otherwise PyTorch' `BCEWithLogitsLoss` (which the model will use) will complain, as explained [here](https://discuss.pytorch.org/t/multi-label-binary-classification-result-type-float-cant-be-cast-to-the-desired-output-type-long/117915/3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AFWlSsbZaRLc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def preprocess_data(examples):\n",
    "    # take a batch of texts\n",
    "    text = examples[\"Tweet\"]\n",
    "    # encode them\n",
    "    encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128)\n",
    "    # add labels\n",
    "    labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
    "    # create numpy array of shape (batch_size, num_labels)\n",
    "    labels_matrix = np.zeros((len(text), len(labels)))\n",
    "    # fill numpy array\n",
    "    for idx, label in enumerate(labels):\n",
    "      labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "      encoding[\"labels\"] = labels_matrix.tolist()\n",
    "  \n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i4ENBTdulBEI",
    "outputId": "02554a1f-4961-461a-bf29-555b8debeabf",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e231a4512e604fa19225701c45f58c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3259 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0enAb0W9o25W",
    "outputId": "55bc5ba6-d169-49c6-f562-bb7ea4143866",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "example = encoded_dataset['train'][0]\n",
    "print(example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "D0McCtJ8HRJY",
    "outputId": "82fb0336-51a3-40ad-ebc0-65eeb7cf4b6c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] “ worry is a down payment on a problem you may never have '. joyce meyer. # motivation # leadership # worry [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(example['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VdIvj6WjHeZQ",
    "outputId": "418c14d2-cca3-44e9-d0a2-6ad4ca7a007c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4Dx95t2o6N9",
    "outputId": "3ce6c923-0b45-4743-bc4b-7771d088b03e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anticipation', 'optimism', 'trust']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgpKXDfvKBxn"
   },
   "source": [
    "Finally, we set the format of our data to PyTorch tensors. This will turn the training, validation and test sets into standard PyTorch [datasets](https://pytorch.org/docs/stable/data.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Lk6Cq9duKBkA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5qSmCgWefWs"
   },
   "source": [
    "## Define model\n",
    "\n",
    "Here we define a model that includes a pre-trained base (i.e. the weights from bert-base-uncased) are loaded, with a random initialized classification head (linear layer) on top. One should fine-tune this head, together with the pre-trained base on a labeled dataset.\n",
    "\n",
    "This is also printed by the warning.\n",
    "\n",
    "We set the `problem_type` to be \"multi_label_classification\", as this will make sure the appropriate loss function is used (namely [`BCEWithLogitsLoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html)). We also make sure the output layer has `len(labels)` output neurons, and we set the id2label and label2id mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6XPL1Z_RegBF",
    "outputId": "22994300-8c93-421e-faa4-678d6cc14aab",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n",
    "                                                           problem_type=\"multi_label_classification\", \n",
    "                                                           num_labels=len(labels),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjJGEXShp7te"
   },
   "source": [
    "## Train the model!\n",
    "\n",
    "We are going to train the model using HuggingFace's Trainer API. This requires us to define 2 things: \n",
    "\n",
    "* `TrainingArguments`, which specify training hyperparameters. All options can be found in the [docs](https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments). Below, we for example specify that we want to evaluate after every epoch of training, we would like to save the model every epoch, we set the learning rate, the batch size to use for training/evaluation, how many epochs to train for, and so on.\n",
    "* a `Trainer` object (docs can be found [here](https://huggingface.co/transformers/main_classes/trainer.html#id1))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "K5a8_vIKqr7P",
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "metric_name = \"f1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dR2GmpvDqbuZ",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiger/.pyenv/versions/3.11.2/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"bert-finetuned-sem_eval-english\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    #push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_v2fPFFJ3-v"
   },
   "source": [
    "We are also going to compute metrics while training. For this, we need to define a `compute_metrics` function, that returns a dictionary with the desired metric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "797b2WHJqUgZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "    \n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fxNo4_TsvzDm"
   },
   "source": [
    "Let's verify a batch as well as a forward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "IlOgGiojuWwG",
    "outputId": "cd0b2c99-b520-468d-8ffc-c36211b7820a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train'][0]['labels'].type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y41Kre_jvD7x",
    "outputId": "b6ca888b-6371-40fb-ab83-3dc24d28320a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  1523,  4737,  2003,  1037,  2091,  7909,  2006,  1037,  3291,\n",
       "         2017,  2089,  2196,  2031,  1005,  1012, 11830, 11527,  1012,  1001,\n",
       "        14354,  1001,  4105,  1001,  4737,   102,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train']['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sxWcnZ8ku12V",
    "outputId": "26522911-c3cd-466a-ae2d-d81d23003c23",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.7272, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), logits=tensor([[-0.5590,  0.6070, -0.3224,  0.0065,  0.4310,  0.1028, -0.6608,  0.2424,\n",
       "         -0.3219,  0.6584,  0.0402]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forward pass\n",
    "outputs = model(input_ids=encoded_dataset['train']['input_ids'][0].unsqueeze(0), labels=encoded_dataset['train'][0]['labels'].unsqueeze(0))\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-X2brZcv0X6"
   },
   "source": [
    "Let's start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "chq_3nUz73ib",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2146/3132099784.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 5.4.143, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/tiger/.pyenv/versions/3.11.2/lib/python3.11/site-packages/bytedmetrics/__init__.py:10: UserWarning: bytedmetrics is renamed to bytedance.metrics, please using `bytedance.metrics` instead of `bytedmetrics`\n",
      "  warnings.warn(\"bytedmetrics is renamed to bytedance.metrics, please using `bytedance.metrics` instead of `bytedmetrics`\")\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KXmFds8js6P8",
    "outputId": "66ebb2ab-f93f-48aa-a4dc-36f55f2f8559",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/home/tiger/.pyenv/versions/3.11.2/lib/python3.11/site-packages/bytedmetrics/__init__.py:10: UserWarning: bytedmetrics is renamed to bytedance.metrics, please using `bytedance.metrics` instead of `bytedmetrics`\n",
      "  warnings.warn(\"bytedmetrics is renamed to bytedance.metrics, please using `bytedance.metrics` instead of `bytedmetrics`\")\n",
      "wandb: ⭐️ View project at https://ml.byteintl.net/experiment/tracking/detail?Id=project_20230126_e9daa974\n",
      "wandb: 🚀 View run at https://ml.byteintl.net/experiment/tracking/detail?Id=project_20230126_e9daa974&selectedTrial=run_20241225_f6ea5471\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f493ed26a008408caaacaa0cd00925fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666878438554704, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.75"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/.jupyter/connection/wandb/run-20241225_063609-run_20241225_f6ea5471</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"\" target=\"_blank\">bert-finetuned-sem_eval-english</a></strong> to <a href=\"\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4275' max='4275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4275/4275 05:50, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.415300</td>\n",
       "      <td>0.314708</td>\n",
       "      <td>0.689254</td>\n",
       "      <td>0.786952</td>\n",
       "      <td>0.282167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.283100</td>\n",
       "      <td>0.303579</td>\n",
       "      <td>0.697483</td>\n",
       "      <td>0.789487</td>\n",
       "      <td>0.286682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.239900</td>\n",
       "      <td>0.307003</td>\n",
       "      <td>0.710793</td>\n",
       "      <td>0.803350</td>\n",
       "      <td>0.279910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.213900</td>\n",
       "      <td>0.312438</td>\n",
       "      <td>0.703557</td>\n",
       "      <td>0.798956</td>\n",
       "      <td>0.274266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.193400</td>\n",
       "      <td>0.311123</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.801270</td>\n",
       "      <td>0.282167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4275, training_loss=0.26133509318033854, metrics={'train_runtime': 370.5878, 'train_samples_per_second': 92.259, 'train_steps_per_second': 11.536, 'total_flos': 2249123476753920.0, 'train_loss': 0.26133509318033854, 'epoch': 5.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fd908240dd0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fd8b0399b10, execution_count=20 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fd89887f610, raw_cell=\"trainer.train()\" store_history=True silent=False shell_futures=True cell_id=2b4f43f3-cc02-44c4-9d2e-8e1c4ae6a061> result=TrainOutput(global_step=4275, training_loss=0.26133509318033854, metrics={'train_runtime': 370.5878, 'train_samples_per_second': 92.259, 'train_steps_per_second': 11.536, 'total_flos': 2249123476753920.0, 'train_loss': 0.26133509318033854, 'epoch': 5.0})>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiloh9eMK91o"
   },
   "source": [
    "## Evaluate\n",
    "\n",
    "After training, we evaluate our model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "cMlebJ83LRYG",
    "outputId": "b18102e7-2198-4beb-c874-d39636f740ed",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fd908240dd0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fd7f83b2010, raw_cell=\"trainer.evaluate()\" store_history=True silent=False shell_futures=True cell_id=9e48f365-54de-4c51-bda6-376b6aa77fb7>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='111' max='111' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [111/111 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3070029318332672,\n",
       " 'eval_f1': 0.7107927883428007,\n",
       " 'eval_roc_auc': 0.8033498188202989,\n",
       " 'eval_accuracy': 0.2799097065462754,\n",
       " 'eval_runtime': 2.3742,\n",
       " 'eval_samples_per_second': 373.176,\n",
       " 'eval_steps_per_second': 46.752,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fd908240dd0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fd7f83b29d0, execution_count=21 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fd7f83b2010, raw_cell=\"trainer.evaluate()\" store_history=True silent=False shell_futures=True cell_id=9e48f365-54de-4c51-bda6-376b6aa77fb7> result={'eval_loss': 0.3070029318332672, 'eval_f1': 0.7107927883428007, 'eval_roc_auc': 0.8033498188202989, 'eval_accuracy': 0.2799097065462754, 'eval_runtime': 2.3742, 'eval_samples_per_second': 373.176, 'eval_steps_per_second': 46.752, 'epoch': 5.0}>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nmvJp0pLq-3"
   },
   "source": [
    "## Inference\n",
    "\n",
    "Let's test the model on a new sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "3fxjfr8PLD42",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fd908240dd0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fd801b8edd0, raw_cell=\"text = \"I'm happy I can finally train a model for ..\" store_history=True silent=False shell_futures=True cell_id=d69a71b1-4033-4c23-bd6f-a8c6257cde46>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fd908240dd0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fd7f83f7550, execution_count=22 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fd801b8edd0, raw_cell=\"text = \"I'm happy I can finally train a model for ..\" store_history=True silent=False shell_futures=True cell_id=d69a71b1-4033-4c23-bd6f-a8c6257cde46> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "text = \"I'm happy I can finally train a model for multi-label classification\"\n",
    "\n",
    "encoding = tokenizer(text, return_tensors=\"pt\")\n",
    "encoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\n",
    "\n",
    "outputs = trainer.model(**encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8THm5-XgNHPm"
   },
   "source": [
    "The logits that come out of the model are of shape (batch_size, num_labels). As we are only forwarding a single sentence through the model, the `batch_size` equals 1. The logits is a tensor that contains the (unnormalized) scores for every individual label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KOBosj4UL2tU",
    "outputId": "be370f49-3840-4c76-b193-76083e49701e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fd908240dd0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fd902313190, raw_cell=\"logits = outputs.logits\n",
      "logits.shape\" store_history=True silent=False shell_futures=True cell_id=06ef6b0a-9104-47df-a182-f9abbb9998c4>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fd908240dd0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fd7f83da710, execution_count=23 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fd902313190, raw_cell=\"logits = outputs.logits\n",
      "logits.shape\" store_history=True silent=False shell_futures=True cell_id=06ef6b0a-9104-47df-a182-f9abbb9998c4> result=torch.Size([1, 11])>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "logits = outputs.logits\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DC4XdDaHNVcd"
   },
   "source": [
    "To turn them into actual predicted labels, we first apply a sigmoid function independently to every score, such that every score is turned into a number between 0 and 1, that can be interpreted as a \"probability\" for how certain the model is that a given class belongs to the input text.\n",
    "\n",
    "Next, we use a threshold (typically, 0.5) to turn every probability into either a 1 (which means, we predict the label for the given example) or a 0 (which means, we don't predict the label for the given example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEkAQleMMT0k",
    "outputId": "fddb51cb-bf01-420a-fd5b-4a7c2e775446",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fd908240dd0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fd7f8346cd0, raw_cell=\"# apply sigmoid + threshold\n",
      "sigmoid = torch.nn.Sig..\" store_history=True silent=False shell_futures=True cell_id=92cf8428-535a-4c5a-a52c-47c4592e2d61>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['joy', 'optimism']\n",
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fd908240dd0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fd7f8345550, execution_count=24 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fd7f8346cd0, raw_cell=\"# apply sigmoid + threshold\n",
      "sigmoid = torch.nn.Sig..\" store_history=True silent=False shell_futures=True cell_id=92cf8428-535a-4c5a-a52c-47c4592e2d61> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# apply sigmoid + threshold\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probs = sigmoid(logits.squeeze().cpu())\n",
    "predictions = np.zeros(probs.shape)\n",
    "predictions[np.where(probs >= 0.5)] = 1\n",
    "# turn predicted id's into actual label names\n",
    "predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMiblo1Ci0GTlAbbA5wB3mn",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Fine-tuning BERT (and friends) for multi-label text classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "656098",
   "language": "",
   "name": "656098"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "091f8220f33241f288faa0612853585f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6111a73e684a47769bda7183a836ee91",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8b1899a0c4b144d7a5e6599f8afb8b65",
      "value": 3
     }
    },
    "1045bb16e3694410898a73cf1b848917": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bbba60f793c14100934a268063f63d26",
      "placeholder": "​",
      "style": "IPY_MODEL_cd3570ddf67541d7818d97e236c54e54",
      "value": " 3/3 [00:00&lt;00:00, 75.93it/s]"
     }
    },
    "308fa6a7348140ec981a8d6c7d31f346": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5080d322a8034924b652b379c04667ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6111a73e684a47769bda7183a836ee91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b1899a0c4b144d7a5e6599f8afb8b65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8bc92587e35443488445e7521fbd0a13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5080d322a8034924b652b379c04667ed",
      "placeholder": "​",
      "style": "IPY_MODEL_cb95e545fbdd4e99903bf634df694c9f",
      "value": "100%"
     }
    },
    "9a1aa9f2cc29473f9f8e5459d2641e76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8bc92587e35443488445e7521fbd0a13",
       "IPY_MODEL_091f8220f33241f288faa0612853585f",
       "IPY_MODEL_1045bb16e3694410898a73cf1b848917"
      ],
      "layout": "IPY_MODEL_308fa6a7348140ec981a8d6c7d31f346"
     }
    },
    "bbba60f793c14100934a268063f63d26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb95e545fbdd4e99903bf634df694c9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd3570ddf67541d7818d97e236c54e54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
