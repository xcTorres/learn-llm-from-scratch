# learn-llm-from-scratch
Learn LLM from scatch

## Fine-tune
#### Bert 
[Token classification Task](./fine-tune/Custom_Named_Entity_Recognition_with_BERT.ipynb)  
[Sequence classification task](./fine-tune/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb)  

#### Vision Transformer
[Finetune Vision transformer task](./fine-tune/Fine_tuning_the_Vision_Transformer_on_CIFAR_10_with_Trainer.ipynbb)

#### MultiModal
[BLIP-2 Demo](./fine-tune/Chat_with_BLIP_2.ipynb)


## SourceCode


## Reference
[Huggingface](https://huggingface.co/docs/transformers/en/model_doc/bert)  
[Transformers-Tutorials](https://github.com/NielsRogge/Transformers-Tutorials/tree/master)
[Pytorch Implementations](https://github.com/lucidrains)


## Paper 
| Category | Paper Link| 
|----------|----------|
| NLP | [Attention Is All You Need](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf) |
| NLP | [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805) |
| CV  | [(ViT) An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)|  
| Multimodal | [BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models](https://arxiv.org/abs/2301.12597)

