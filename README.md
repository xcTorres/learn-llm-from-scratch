# learn-llm-from-scratch
Learn LLM from scatch

## Fine-tune
#### Bert 
[BertForTokenClassification to do NER task](./fine-tune/Custom_Named_Entity_Recognition_with_BERT.ipynb)  
[AutoModelForSequenceClassification to do sequence classification task](./fine-tune/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb)  

#### Vision Transformer
[Finetune Vision transformer task](./fine-tune/Fine_tuning_the_Vision_Transformer_on_CIFAR_10_with_Trainer.ipynbb)


## SourceCode


## Code Reference
[Huggingface]([https://huggingface.co/docs/transformers/en/model_doc/bert])  
[Transformers-Tutorials](https://github.com/NielsRogge/Transformers-Tutorials/tree/master)


## Paper 
| Category | Paper Link| 
|----------|----------|
| NLP | [Attention Is All You Need](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf) |
| NLP | [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805) |
| CV| [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)|

